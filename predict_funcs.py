from scapy.all import *
import pandas as pd
import joblib
from sklearn.ensemble import RandomForestClassifier
import gettls

#按照session分割packets
def split_pkts(pkts):
    session_dict={}
    for aPkt in pkts:
        if TCP in aPkt:
            try:
                aPkt[IP]
            except :
                continue
            ipSrc = aPkt[IP].src
            tcpSport = aPkt[TCP].sport
            ipDst = aPkt[IP].dst
            tcpDport = aPkt[TCP].dport
            if ipSrc > ipDst:
                key = ipSrc + "-" + str(tcpSport) + "_" + ipDst + "-" + str(tcpDport)
            elif ipSrc < ipDst:
                key = ipDst + "-" + str(tcpDport) + "_" + ipSrc + "-" + str(tcpSport)
            elif tcpSport > tcpDport:
                key=ipSrc + "-" + str(tcpSport) + "_" + ipDst + "-" + str(tcpDport) 
            else:
                key= ipDst + "-" + str(tcpDport) + "_" + ipSrc + "-" + str(tcpSport)
            if key not in session_dict:
                session_dict[key]=[aPkt,]
            else :
                session_dict[key].append(aPkt)
    return session_dict

##从一个session中得到features
def get_pkts_features(session_dict):
    features=[]
    TLSPD = gettls.TLSPcapDecode()
    for sessions in session_dict.values():
        session_statistic_features = gettls.get_session_statistic_feature(sessions, TLSPD)
        if not session_statistic_features:
            continue
        features.append(session_statistic_features)
    return features

##cs_vector和ext_cevtor分列
def split_vector_str(vector_str):
    return vector_str[1:-1].split(", ")

##单行特征分列
def get_split_feature(features):
    cs_vec = features[-5][:100]
    ext_vec = features[-4][:50]
    split_feature = features[2:14]+cs_vec+ext_vec+features[-3:]
    return split_feature

##多行特征分列
def get_split_features(all_features):
    return list(map(get_split_feature,all_features))

##预测pcap文件
def predict_pcap(file):   
    pkts= rdpcap(file)
    return predict_pkts(pkts)
    
##预测packets类型
def predict_pkts(pkts):
    if not len(pkts):
        return False
    clf = joblib.load('model/new_random_forest_model.pkl')
    session_dict=split_pkts(pkts)
    if not len(session_dict):
        return False
    input_features = get_pkts_features(session_dict)
    if not len(input_features):
        return False
    try:
        predict_result = clf.predict(get_split_features(input_features))
    except Exception as e:
        print('预测出错---------------------')
        traceback.print_exc()
        return False
    else :
        print(predict_result)
        num_of_good = (predict_result == 'good').sum()
        num_of_bad = len(predict_result)-num_of_good
        print('正常流量数：%d'%num_of_good)
        print('恶意流量数：%d'%num_of_bad)
        label = pd.Series(predict_result).value_counts().index[0]
        print('流量类别：'+label)
    return num_of_good,num_of_bad,label